# Sentiments_Analysis_using_RNN
We will learn how to use a reccurent neural network (RNN)to do the following:  Sentiment Analysis

The formal definition of this term from Wikipedia is as follows:

the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral.

The example we’ll use here is classifying movie reviews as either postive, negative or neutral.
We had Used Tensorflow for building this Model.

Python Code Explaination::

**Step 1**
Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset.
********************************************************************************************************
from keras.datasets import imdb
from keras.preprocessing import sequence
import keras
import tensorflow as tf
import os
import numpy as np

VOCAB_SIZE = 88584

MAXLEN = 250
BATCH_SIZE = 64

(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)
************************************************************************************************************
**Step 2 (More Processing)** 
If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:

if the review is greater than 250 words then trim off the extra words
if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.
Luckily for us keras has a function that can do this for us:
*********************************************************************************************************
train_data = sequence.pad_sequences(train_data, MAXLEN)
test_data = sequence.pad_sequences(test_data, MAXLEN)
*********************************************************************************************************

**Step3 (Creating the Model)**
Now it's time to create the model. We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment.

32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!
*********************************************************************************************************
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(VOCAB_SIZE, 32),
    tf.keras.layers.LSTM(32),
    tf.keras.layers.Dense(1, activation="sigmoid")
])
model.summary()  /* see the model*/
*********************************************************************************************************

**Step4 (Training)**
Now it's time to compile and train the model.
*********************************************************************************************************
model.compile(loss="binary_crossentropy",optimizer="rmsprop",metrics=['acc'])

history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)
*********************************************************************************************************

**Step6 (Evaluation)**
And we'll evaluate the model on our training data to see how well it performs.
*********************************************************************************************************
results = model.evaluate(test_data, test_labels)
print(results)
*********************************************************************************************************


**Step7 (Making Prediction)

Now let’s use our network to make predictions on our own reviews.

Since our reviews are encoded well need to convert any review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data.

*********************************************************************************************************
word_index = imdb.get_word_index()

def encode_text(text):           //Encoder function for input string to convert in the format which is compatible for getting prediction
  tokens = keras.preprocessing.text.text_to_word_sequence(text)
  tokens = [word_index[word] if word in word_index else 0 for word in tokens]
  return sequence.pad_sequences([tokens], MAXLEN)[0]

text = "that movie was just amazing, so amazing"
encoded = encode_text(text)
print(encoded)

reverse_word_index = {value: key for (key, value) in word_index.items()}        

def decode_integers(integers):           ///Decoder Funtion for conversion of nummpy format to a valid sting or sentance
    PAD = 0
    text = ""
    for num in integers:
      if num != PAD:
        text += reverse_word_index[num] + " "

    return text[:-1]
  
print(decode_integers(encoded))


def predict(text):
  encoded_text = encode_text(text)
  pred = np.zeros((1,250))
  pred[0] = encoded_text
  result = model.predict(pred)
  print(result[0])

positive_review = "very nice and amazing movie"
predict(positive_review)                //How much is the imput string is positive 

*********************************************************************************************************
 **Step9(Saving The Model)**
 
*********************************************************************************************************
model.save("Sentiments_analysis.h5")
*********************************************************************************************************
